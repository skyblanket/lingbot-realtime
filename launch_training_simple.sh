#!/bin/bash
# Simple DMD training launcher for 4x H200s
# Uses simplified approach without full Wan modules

set -e

echo "ðŸš€ LingBot-World DMD Training on 4x H200s"
echo "=========================================="

# Install required packages
pip install -q diffusers transformers accelerate

# Create simple training script
cat > train_simple.py << 'EOF'
#!/usr/bin/env python3
"""Simplified DMD training without full Wan dependencies"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from diffusers import AutoencoderKLWan, WanPipeline
from transformers import UMT5EncoderModel, AutoTokenizer
import numpy as np
from pathlib import Path
import cv2
import sys
sys.path.insert(0, '/workspace/lingbot-realtime')

from lingbot_causal.causal_model import CausalWanModel
from lingbot_causal.weight_loader import LingBotWeightLoader

class SimpleDataset:
    def __init__(self, video_dir):
        self.files = list(Path(video_dir).glob("*.mp4"))
    def __len__(self): return len(self.files)
    def __getitem__(self, idx):
        return {'video': torch.randn(3, 17, 512, 512), 'text': 'walking forward'}

def main():
    device = 'cuda'
    print("Loading models...")
    
    # Load causal model
    model = CausalWanModel(dim=5120, num_heads=40, num_layers=40,
                          ffn_dim=13824, text_len=512).to(device).to(torch.bfloat16)
    
    loader = LingBotWeightLoader('/workspace/lingbot-world')
    loader.load_into_causal_model(model, device=device)
    
    # Load VAE from diffusers
    vae = AutoencoderKLWan.from_pretrained(
        "Wan-AI/Wan2.1-T2V-14B",
        subfolder="vae",
        torch_dtype=torch.bfloat16
    ).to(device)
    
    # Load text encoder
    text_encoder = UMT5EncoderModel.from_pretrained(
        "google/umt5-xxl",
        torch_dtype=torch.bfloat16
    ).to(device)
    tokenizer = AutoTokenizer.from_pretrained("google/umt5-xxl")
    
    print("Models loaded! Starting training...")
    
    # Simple training loop
    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)
    
    for step in range(10000):
        # Dummy batch for now
        latent = torch.randn(1, 16, 17, 32, 32, device=device, dtype=torch.bfloat16)
        t = torch.tensor([500], device=device)
        
        # Forward
        with torch.cuda.amp.autocast(dtype=torch.bfloat16):
            output = model.forward_train([latent], t, [torch.randn(1, 512, 5120, device=device)], 17, None, [latent[:, :, :1]])
            loss = output.mean()
        
        # Backward
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        if step % 50 == 0:
            print(f"Step {step}: loss = {loss.item():.4f}")
        
        if step % 1000 == 0 and step > 0:
            torch.save(model.state_dict(), f"checkpoint_step_{step}.pt")
            print(f"Saved checkpoint at step {step}")
    
    print("Training complete!")

if __name__ == "__main__":
    main()
EOF

# Run training
python3 train_simple.py 2>&1 | tee training_simple.log
